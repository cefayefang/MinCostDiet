{"cells":[{"cell_type":"markdown","id":"6c5b82b7-5c24-4317-8f85-97ec70ae7580","metadata":{},"source":["## Introduction\n\n"]},{"cell_type":"markdown","id":"e59bc00a-5ff4-47cc-8123-4dfc0bbfe8c9","metadata":{},"source":["We're thinking about the problem of finding the cheapest possible\nnutritious diet. As we have discussed, this can be set up as a linear program.\n\n$$\n    \\min_x p'x\n$$\n\nsuch that\n$$\nAx \\geq b\n$$\n\nwhere $p$ is a vector of prices, $A$ is a matrix that maps\nvectors of quantities of food into vectors of nutrients, and where $b$ is a vector of nutrient constraints.\n\nThe goal of this notebook is to expose the class to some additional data sources and to generate a minimum cost diet for the United States using recent national average price data.\n\n"]},{"cell_type":"markdown","id":"e8345654-7569-4098-87a7-9104ceb4e69c","metadata":{},"source":["## Food and Nutrient Data\n\n"]},{"cell_type":"markdown","id":"bb8902b5-fcd4-4cce-969d-8477b7d0e295","metadata":{},"source":["The USDA maintains a database of foods called the [FNDDS](https://www.ars.usda.gov/northeast-area/beltsville-md-bhnrc/beltsville-human-nutrition-research-center/food-surveys-research-group/docs/fndds/) (Food and Nutrition Database for Dietary Studies). In it, they define \"recipes,\" which are made up of \"ingredients.\" There are one or more ingredients per recipe. Ingredients are then mapped to nutrients in terms of nutrient units per hectogram (100g) of an ingredient. Thus, using these mappings, we can generate a FNDDS recipe-level food-to-nutrient matrix we can use as our \"A\" matrix.\n\nLets first define a helper function we will use to make sure ids are formatted similarly (to help with dataframe merging). \n\n"]},{"cell_type":"code","execution_count":1,"id":"99b2e949-cf90-4fd0-9607-02417932780f","metadata":{},"outputs":[],"source":["def format_id(id,zeropadding=0):\n    \"\"\"Nice string format for any id, string or numeric.\n\n    Optional zeropadding parameter takes an integer\n    formats as {id:0z} where\n    \"\"\"\n    if pd.isnull(id) or id in ['','.']: return None\n\n    try:  # If numeric, return as string int\n        return ('%d' % id).zfill(zeropadding)\n    except TypeError:  # Not numeric\n        return id.split('.')[0].strip().zfill(zeropadding)\n    except ValueError:\n        return None\n\ndata_url = \"https://docs.google.com/spreadsheets/d/12Z4n8HbFZRYvH6B-D8EDLDibRiL50zNMlSBLMJ41C1o/\""]},{"cell_type":"markdown","id":"32d6649b-327d-48f7-9c91-0a8f6358361a","metadata":{},"source":["Lets load in the recipes and see what we have.\n\n"]},{"cell_type":"code","execution_count":1,"id":"589bed20-530c-4dd9-b437-f731148764c3","metadata":{},"outputs":[],"source":["import pandas as pd\nfrom eep153_tools.sheets import read_sheets\n\nrecipes = read_sheets(data_url, sheet=\"recipes\")\nrecipes = (recipes\n           .assign(parent_foodcode = lambda df: df[\"parent_foodcode\"].apply(format_id),\n                   ingred_code = lambda df: df[\"ingred_code\"].apply(format_id))\n           .rename(columns={\"parent_desc\": \"recipe\"}))\n\n\n# lets see an example of a recipe.\nrecipes[recipes[\"recipe\"].str.contains(\"Vegetable lasagna\", case=False)]"]},{"cell_type":"markdown","id":"fff93352-04a6-4fd7-a373-9bc24f56e036","metadata":{},"source":["And we can take a look at the ingredients. I'll call this dataframe \"nutrition\" because that's what we really care about in here.\n\n"]},{"cell_type":"code","execution_count":1,"id":"0a3e6f2c-3e6f-4817-8386-c6186ac0f755","metadata":{},"outputs":[],"source":["nutrition = (read_sheets(data_url, sheet=\"nutrients\")\n             .assign(ingred_code = lambda df: df[\"ingred_code\"].apply(format_id)))\n\ndisplay(nutrition.head())\nnutrition.columns"]},{"cell_type":"markdown","id":"e1f9959b-f941-40eb-959f-d8c7ad01d722","metadata":{},"source":["Lets merge these mappings to end up with a matrix of recipes and their nutrients as measured by units of a nutrient per 100 grams of that food.\n\n"]},{"cell_type":"code","execution_count":1,"id":"c65d2c14-281f-4229-aa85-08d372cd959d","metadata":{},"outputs":[],"source":["# normalize weights to percentage terms. \nrecipes['ingred_wt'] = recipes['ingred_wt']/recipes.groupby(['parent_foodcode'])['ingred_wt'].transform(\"sum\")\n\n# we're going to extend the recipes data frame to include the nutrient profiles of its ingredients (in 100g)\ndf = recipes.merge(nutrition, how=\"left\", on=\"ingred_code\")\n\n# multiply all nutrients per 100g of an ingredient by the weight of that ingredient in a recipe.\nnumeric_cols = list(df.select_dtypes(include=[\"number\"]).columns)\nnumeric_cols.remove(\"ingred_wt\")\ndf[numeric_cols] = df[numeric_cols].mul(df[\"ingred_wt\"], axis=0)\n\n# sum nutrients of food codes (over the multiple ingredients)\n# python tip: one can merge dictionaries dict1 dict2 using **, that is: dict_merge = {**dict1, **dict2}. The ** effectively \"unpacks\" the key value pairs in each dictionary\ndf = df.groupby('parent_foodcode').agg({**{col: \"sum\" for col in numeric_cols},\n                                        \"recipe\": \"first\"})\n\ndf.index.name = \"recipe_id\"\n\nfood_names = df[\"recipe\"]\n\ndf.head()"]},{"cell_type":"markdown","id":"71d57c07-f803-4b3f-b1d5-552ec6312fa2","metadata":{},"source":["If we recall, the $ A  $ matrix maps foods into constrained nutrients. This is effectively the transpose of our `df`. We'll have to do more before we create `A` - not all of these nutrients are constrained, and unfortunately, we won't have prices for all foods.\n\n"]},{"cell_type":"markdown","id":"7f948c62-ed39-4b97-a944-ce560ebdffe8","metadata":{},"source":["## Prices\n\n"]},{"cell_type":"markdown","id":"32633790-6ea0-4680-91de-109836b5e441","metadata":{},"source":["Now that we have the bones of the matrix $ A $, lets next consider the price vector $ p $. The USDA generates national average prices ([Purchase to Plate](https://www.ers.usda.gov/data-products/purchase-to-plate)) for these FNDDS foods using scanner data from grocery stores all over the country. These are in USD per 100 grams of a recipe. They have been doing this for a while, and they produce the prices in two-year batches.\n\n"]},{"cell_type":"code","execution_count":1,"id":"51b7bbb9-b510-4cda-a220-dd27ee1e78c0","metadata":{},"outputs":[],"source":["prices = read_sheets(data_url, sheet=\"prices\")[[\"food_code\", \"year\", \"price\"]]\n\nprices[\"food_code\"] = prices[\"food_code\"].apply(format_id)\n\nprices = prices.set_index([\"year\", \"food_code\"])\nprint(prices.index.levels[0])\n\n# we'll focus on the latest price data\nprices = prices.xs(\"2017/2018\", level=\"year\")\n\n# drop rows of prices where the price is \"NA\"\nprices = prices.dropna(subset=\"price\")\n\nprint(f\"We have prices for {prices.shape[0]} unique recipes (FNDDS food codes)\")"]},{"cell_type":"markdown","id":"b620813e-93a1-44e3-8b52-691fbbd2493a","metadata":{},"source":["## Dietary Requirements\n\n"]},{"cell_type":"markdown","id":"57be68a6-448b-43a6-b066-af68ed0f66b5","metadata":{},"source":["As before, we'll get our dietary requirements from the USDA.\n\n"]},{"cell_type":"code","execution_count":1,"id":"857d02d6-6ed0-4f9c-912d-d1302a29c22d","metadata":{},"outputs":[],"source":["rda = read_sheets(data_url, sheet=\"rda\")\n\nrda = rda.set_index(\"Nutrient\")\n\nrda.columns"]},{"cell_type":"markdown","id":"eee448d0-702e-46d6-9ff3-3fda129922e4","metadata":{},"source":["## Putting It All Together\n\n"]},{"cell_type":"markdown","id":"b3a14fd3-bd7b-4fc6-8497-0e1792c48d48","metadata":{},"source":["Earlier, we generated a dataframe of foods and nutrients. This included something like 65 different nutrients over 8,900 recipes! Unfortunately, our price data far fewer foods, so we have to narrow the set of foods from which we are choosing. I'll solve this issue by taking the set intersection of the two sets of food codes, and then select those common food codes from both dataframes.\n\n"]},{"cell_type":"code","execution_count":1,"id":"691cccae-1732-4a87-8cb4-e0006b31b955","metadata":{},"outputs":[],"source":["common_recipes = df.index.intersection(prices.index)\n\n# python tip: given a list of indices, \"loc\" both subsets and sorts. \ndf = df.loc[common_recipes]\nprices = prices.loc[common_recipes]\n\n# lets remap the price dataframe index to be the actual food names.\nprices.index = prices.index.map(food_names)\n\nA_all = df.T"]},{"cell_type":"markdown","id":"58a939e7-3032-44d0-9cb4-0c97e877ab56","metadata":{},"source":["A<sub>all</sub> will have the same number of foods as p has prices, but we now must to trim down the number of nutrients to include only those for which we have constraints. We'll look at the shapes of all these objects to be sure that the matrix multiplication operations are well defined.\n\n"]},{"cell_type":"code","execution_count":1,"id":"82eea0a8-c4b7-446f-91c6-7c45a9a350a5","metadata":{},"outputs":[],"source":["# pick a demographic (column from rda dataframe)\n'''\nselect from \n['Child_1_3', 'Female_4_8', 'Male_4_8', 'Female_9_13', 'Male_9_13', \n'Female_14_18', 'Male_14_18','Female_19_30', 'Male_19_30', \n'Female_31_50', 'Male_31_50', 'Female_51U', 'Male_51U']\n'''\ngroup = \"Female_19_30\"\n\n# create lower bounds and upper bounds.\nbmin = rda.loc[rda['Constraint Type'].isin(['RDA', 'AI']), group]\nbmax = rda.loc[rda['Constraint Type'].isin(['UL']), group]\n\n# reindex ensures we only keep nutrients in bmin/bmax\nAmin = A_all.reindex(bmin.index).dropna(how='all')\nAmax = A_all.reindex(bmax.index).dropna(how='all')\n\nb = pd.concat([bmin, -bmax])\nA = pd.concat([Amin, -Amax])\n\n#python tip: by typing \"=\" after the variable name inside the curly braces, it formats the output so we don't have to write f\"variable = {variable}\"\nprint(f\"{bmin.shape=}\")\nprint(f\"{Amin.shape=}\")\nprint(f\"{bmax.shape=}\")\nprint(f\"{Amax.shape=}\")\nprint(f\"{b.shape=}\")\nprint(f\"{A.shape=}\")\nprint(f\"{prices.shape=}\")"]},{"cell_type":"markdown","id":"e1b5b9ba-fc14-4284-980b-f3279239bf6f","metadata":{},"source":["## Solving the Problem\n\n"]},{"cell_type":"markdown","id":"0bc69135-453c-4c9d-bf45-af683cd7e344","metadata":{},"source":["First, we find a solution to the problem\n\n"]},{"cell_type":"code","execution_count":1,"id":"72936e70-d3f8-4381-95b8-73e1216f5905","metadata":{},"outputs":[],"source":["from  scipy.optimize import linprog as lp\nimport numpy as np\np = prices\ntol = 1e-6 # Numbers in solution smaller than this (in absolute value) treated as zeros\nresult = lp(p, -A, -b, method='highs')\n\nresult"]},{"cell_type":"markdown","id":"156241e7-c28d-4004-aace-21c36162f5a0","metadata":{},"source":["Let's interpret this.  Start with the cost of the solution:\n\n"]},{"cell_type":"code","execution_count":1,"id":"259d29dd-e77b-463e-b17f-f03aa2eece92","metadata":{},"outputs":[],"source":["print(f\"Cost of diet for {group} is ${result.fun:.2f} per day.\")"]},{"cell_type":"markdown","id":"be898428-6d74-4ae0-ba49-b2a3a0ead0d8","metadata":{},"source":["Next, what is it we're actually eating?\n\n"]},{"cell_type":"code","execution_count":1,"id":"c577680d-dade-4dcb-87f5-45966fde0d2e","metadata":{},"outputs":[],"source":["# lets mess with the index on price df so they are recipe names not ids.\n\n# get the result x in a series with food names\ndiet = pd.Series(result.x,index=prices.index)\n\nprint(\"\\nYou'll be eating (in 100s of grams or milliliters):\")\nprint(round(diet[diet >= tol], 2))"]},{"cell_type":"markdown","id":"f65a9d56-404d-4fdf-af63-b4de6b7018ce","metadata":{},"source":["Given this diet, what are nutritional outcomes?\n\n"]},{"cell_type":"code","execution_count":1,"id":"0096c563-76ef-4b08-939f-da49d2d9f3d5","metadata":{},"outputs":[],"source":["tab = pd.DataFrame({\"Outcome\":A.to_numpy()@diet.to_numpy(),\"Recommendation\":np.abs(b)})\nprint(\"\\nWith the following nutritional outcomes of interest:\")\nprint(tab)"]},{"cell_type":"markdown","id":"ad720f64-fb7f-4952-9803-d10d23de0795","metadata":{},"source":["Finally, what are the constraints that bind?  Finding a less expensive\ndiet might involve finding less expensive sources for these particular nutrients.\n\n"]},{"cell_type":"code","execution_count":1,"id":"80a311d6-efc4-4e0e-9eb2-27a581663e46","metadata":{},"outputs":[],"source":["print(\"\\nConstraining nutrients are:\")\nexcess = tab.diff(axis=1).iloc[:,1]\nprint(excess.loc[np.abs(excess) < tol].index.tolist())"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":5}